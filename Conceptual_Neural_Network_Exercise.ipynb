{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conceptual Neural Network Exercise.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPbXyKyJWbG1DMczaCO7TaG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alupo933/Clustering-Work-for-Machine-Learning/blob/main/Conceptual_Neural_Network_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Run the network. What do you notice?\n",
        "\n",
        "- I notice the background of the output moving and adjusting to the same layer background as the nueron. I also noticed a test loss of 0.51 and TRaining loss of 0.49.\n",
        "2. Now, increase the number of neurons in the hidden layer and try changing the activation function to something other than \"Linear.\" Can you model the data now? How many neurons and what activation function allows you to effectively model the data?\n",
        "- Yes I can model the data now. I found 4 neurons and the Tanh allows me to effectively and quickly model the data.\n",
        "3. Feel free to add more neurons, layers, or change anything you would like - can you model the data so that the testing loss is 0.01 or less? What is the smallest number of neurons and layers you can use that gives a test loss of 0.01 or less?\n",
        "- The above testing, 4 neurons and Tanh gives me a testing loss better than 0.01. \n",
        "- ReLU activation , 2 hidden layers and 3 neurons in each layer gives me a test loss of 0.001.\n",
        "4. Play around with the learning rate. What do you notice? Based on this, what do you think the learning rate is?\n",
        "- I notice the higher the learning rate, the more error is found in the output. \n",
        "- I think the learning rate is the ratio the model over fits, based off of the Error it originally finds. The higher the learning rate, the lower the accuracy for more complex problems. AKA it is less likely to pick up white noise."
      ],
      "metadata": {
        "id": "R6A4anCbKal4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Yo3lEQSKWS8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}